{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Generating-Music-v2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMqshJxcsW6gRWvpjsgNDMb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"BT5LZvH9sfvy","colab_type":"text"},"source":["# Initilization"]},{"cell_type":"code","metadata":{"id":"4a3CsU5B4j7t","colab_type":"code","outputId":"3411300a-f5f8-47dd-a669-6d810dabcb88","executionInfo":{"status":"ok","timestamp":1585888585377,"user_tz":240,"elapsed":3841,"user":{"displayName":"Thang Pham","photoUrl":"https://lh6.googleusercontent.com/-m9OaFsJMfho/AAAAAAAAAAI/AAAAAAAAAC4/zgzWztcdT78/s64/photo.jpg","userId":"14610559106662224301"}},"colab":{"base_uri":"https://localhost:8080/","height":394}},"source":["!mkdir -p models\n","!wget \"https://drive.google.com/uc?id=1E95HNEYQI1R-UTuYwJOycrYDJxFxiICC&export=download\" -O songs.p"],"execution_count":1,"outputs":[{"output_type":"stream","text":["--2020-04-03 04:35:47--  https://drive.google.com/uc?id=1E95HNEYQI1R-UTuYwJOycrYDJxFxiICC&export=download\n","Resolving drive.google.com (drive.google.com)... 64.233.189.101, 64.233.189.138, 64.233.189.113, ...\n","Connecting to drive.google.com (drive.google.com)|64.233.189.101|:443... connected.\n","HTTP request sent, awaiting response... 302 Moved Temporarily\n","Location: https://doc-08-3s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ot62h577od63001q9c1k4omk7bp23t03/1585888500000/14610559106662224301/*/1E95HNEYQI1R-UTuYwJOycrYDJxFxiICC?e=download [following]\n","Warning: wildcards not supported in HTTP.\n","--2020-04-03 04:35:47--  https://doc-08-3s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ot62h577od63001q9c1k4omk7bp23t03/1585888500000/14610559106662224301/*/1E95HNEYQI1R-UTuYwJOycrYDJxFxiICC?e=download\n","Resolving doc-08-3s-docs.googleusercontent.com (doc-08-3s-docs.googleusercontent.com)... 74.125.203.132, 2404:6800:4008:c03::84\n","Connecting to doc-08-3s-docs.googleusercontent.com (doc-08-3s-docs.googleusercontent.com)|74.125.203.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 347790 (340K) [text/x-pascal]\n","Saving to: ‘songs.p’\n","\n","songs.p             100%[===================>] 339.64K  --.-KB/s    in 0.002s  \n","\n","2020-04-03 04:35:47 (140 MB/s) - ‘songs.p’ saved [347790/347790]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OhklPLtv4nL1","colab_type":"text"},"source":["# Dataset Preparation"]},{"cell_type":"code","metadata":{"id":"MdwCBwQ2GgTP","colab_type":"code","outputId":"90e927da-1bcf-4625-de8b-b0c44f2ec13a","executionInfo":{"status":"ok","timestamp":1585888587487,"user_tz":240,"elapsed":5910,"user":{"displayName":"Thang Pham","photoUrl":"https://lh6.googleusercontent.com/-m9OaFsJMfho/AAAAAAAAAAI/AAAAAAAAAC4/zgzWztcdT78/s64/photo.jpg","userId":"14610559106662224301"}},"colab":{"base_uri":"https://localhost:8080/","height":633}},"source":["%pylab inline\n","import pickle\n","import pandas as pd\n","import keras\n","from music21 import converter, instrument, note, chord, stream\n","from keras.models import Sequential, load_model\n","from keras.layers import LSTM, Bidirectional, Dropout, Dense, Activation\n","from keras.callbacks import ModelCheckpoint, History\n","\n","# implementation based on https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5\n","def generate_dataset():\n","  \"\"\"datas preprocessing based on a list of song objects, each song object contains song's name and a sequence of notes\"\"\"\n","  songs = pickle.load(open(\"songs.p\", \"rb\"))\n","\n","  # get a list of all notes in all songs\n","  notes = []\n","  for song in songs:\n","    notes += song[\"notes\"]\n","\n","  # n_vocab is the number of unique netes\n","  n_vocab = len(set(notes))\n","\n","  # length of input sequence to LSTM network \n","  sequence_length = 100\n","  # get all pitch names\n","  pitchnames = sorted(set(item for item in notes))\n","  # create a dictionary to map pitches to integers\n","  note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n","  int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n","\n","  network_input = []\n","  network_output = []\n","  # create input sequences and the corresponding outputs\n","  for song in songs:\n","    print(\"Loading\", song[\"name\"])\n","    notes = song[\"notes\"]\n","\n","    for i in range(0, len(notes) - sequence_length, 1):\n","        sequence_in = notes[i : i + sequence_length]\n","        sequence_out = notes[i + sequence_length]\n","        network_input.append([note_to_int[char] for char in sequence_in])\n","        network_output.append(note_to_int[sequence_out])\n","\n","  n_patterns = len(network_input)\n","  # reshape the input into a format compatible with LSTM layers\n","  network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n","  # normalize input\n","  network_input = network_input / float(n_vocab)\n","  network_output = keras.utils.to_categorical(network_output)\n","\n","  return (n_vocab, int_to_note, network_input, network_output)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Populating the interactive namespace from numpy and matplotlib\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"AbacUBiKKlA4","colab_type":"text"},"source":["# Create Network"]},{"cell_type":"code","metadata":{"id":"wO8H90zWKwRq","colab_type":"code","colab":{}},"source":["def create_network(network_input, n_vocab):\n","    \"\"\"create network structure\"\"\"\n","    model = Sequential()\n","    model.add(LSTM(512,input_shape=(network_input.shape[1], network_input.shape[2]),return_sequences=True))\n","    model.add(Dropout(0.5))\n","    model.add(Bidirectional(LSTM(512, return_sequences=True)))\n","    model.add(Dropout(0.5))\n","    model.add(Bidirectional(LSTM(512)))\n","    model.add(Dense(512))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(n_vocab))\n","    model.add(Activation('softmax'))\n","    model.compile(loss='categorical_crossentropy', optimizer='adam')\n","\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_pBP0ZJ1MSGq","colab_type":"text"},"source":["# Train Network"]},{"cell_type":"code","metadata":{"id":"UZ18Kx1_MW-j","colab_type":"code","colab":{}},"source":["def train_network():\n","  \"\"\"train the network\"\"\"\n","  (n_vocab, _, network_input, network_output) = generate_dataset()\n","\n","  # get model structure\n","  model = create_network(network_input, n_vocab)\n","  model.summary()\n","\n","  # callbacks\n","  history = History()\n","  filepath = 'models/model-{epoch:02d}-{loss:.2f}-{val_loss:.2f}.hdf5'\n","  checkpoint_cb = ModelCheckpoint(\n","      filepath, monitor='loss', verbose=0, save_best_only=True, mode='min'\n","  )\n","\n","  # start training the model\n","  n_epoch = 20\n","  model.fit(network_input, network_output, epochs=n_epoch, batch_size=64, validation_split=0.2,\n","            callbacks=[history, checkpoint_cb])\n","  model.save('music_generate_model.h5')\n","\n","  # Plot the model losses\n","  pd.DataFrame(history.history).plot()\n","  plt.savefig('network_loss_per_epoch.png', transparent=True)\n","  plt.close()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0R4HkpAFvLuc","colab_type":"text"},"source":["# Model Prediction"]},{"cell_type":"code","metadata":{"id":"q16ntAmAvX-a","colab_type":"code","outputId":"8350195f-62d2-4983-8c61-fd1560ead32a","executionInfo":{"status":"ok","timestamp":1585889444865,"user_tz":240,"elapsed":124635,"user":{"displayName":"Thang Pham","photoUrl":"https://lh6.googleusercontent.com/-m9OaFsJMfho/AAAAAAAAAAI/AAAAAAAAAC4/zgzWztcdT78/s64/photo.jpg","userId":"14610559106662224301"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Model predicion's implementation based on https://github.com/corynguyen19/midi-lstm-gan\n","\n","def generate_notes(model):\n","    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n","    (n_vocab, int_to_note, network_input, _) = generate_dataset()\n","\n","    # pick a random sequence from the input as a starting point for the prediction  \n","    start = np.random.randint(0, len(network_input) - 1)\n","\n","    pattern = network_input[start]\n","    prediction_output = []\n","\n","    # generate 500 notes\n","    for i in range(500):\n","        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n","        prediction_input = prediction_input / float(n_vocab)\n","\n","        prediction = model.predict(prediction_input, verbose=0)\n","\n","        # random choose from a distribution\n","        index = np.random.choice(n_vocab, 1, p=prediction[0])[0]\n","        # index = np.argmax(prediction)\n","        result = int_to_note[index]\n","        prediction_output.append(result)\n","\n","        print(result)\n","        \n","        pattern = np.append(pattern, index)\n","        pattern = pattern[1 : len(pattern)]\n","\n","    return prediction_output\n","  \n","\n","def create_midi(prediction_output, filename):\n","    \"\"\" convert the output from the prediction to notes and create a midi file\n","        from the notes \"\"\"\n","    offset = 0\n","    output_notes = []\n","\n","    # create note and chord objects based on the values generated by the model\n","    for pattern in prediction_output:\n","        # pattern is a chord\n","        if ('.' in pattern) or pattern.isdigit():\n","            notes_in_chord = pattern.split('.')\n","            notes = []\n","            for current_note in notes_in_chord:\n","                new_note = note.Note(int(current_note))\n","                new_note.storedInstrument = instrument.Piano()\n","                notes.append(new_note)\n","            new_chord = chord.Chord(notes)\n","            new_chord.offset = offset\n","            output_notes.append(new_chord)\n","        # pattern is a note\n","        else:\n","            new_note = note.Note(pattern)\n","            new_note.offset = offset\n","            new_note.storedInstrument = instrument.Piano()\n","            output_notes.append(new_note)\n","        # increase offset each iteration so that notes do not stack\n","        offset += 0.5\n","\n","    midi_stream = stream.Stream(output_notes)\n","    midi_stream.write('midi', fp='{}.mid'.format(filename))\n","\n","model = load_model('/content/models/model-20-1.53-6.50.hdf5')\n","prediction_output = generate_notes(model)\n","create_midi(prediction_output, 'test')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Loading I Will (From \\\"Ao Haru Ride\\\")\n","Loading Sword Art Online A Tender Feeling\n","Loading Sword Art Online At Our Parting\n","Loading New Empire - A Little Braver\n","Loading La Corda d'Oro Tsumugareru Kioku\n","Loading VIXX - Error\n","Loading Euterpe MIDI\n","Loading Diabolik Lovers - Yui\n","Loading Ignite - Sword Art Online\n","Loading Aqua Terrarium \n","Loading UtaPri Heavens Gate (Orchestra)\n","Loading UtaPri Sanctuary\n","Loading Nana - A little pain-1\n","Loading Goblin - Beautiful (AnimeMidi)\n","Loading NieR - Weight of the World (Solo)\n","Loading Vogel im Ka_fig\n","Loading Diabolik Lovers - Rosary\n","Loading UtaPri Rainbow Dream\n","Loading Senjougahara Tore @\n","Loading Catch the Moment SAO\n","Loading A Werewolf Boy - A Werewolf Boy\n","Loading Brothers Conflict BelovedXSurvival\n","Loading Angel Beats! - Ichiban no Takaramono 2017\n","Loading Hiiro no Kakera - Nee (AnimeMidi)\n","Loading Tetsukazu no Kanjou (Piano Solo)\n","Loading Dango Daikazoku\n","Loading BTS - Go Go (AnimeMidi)\n","Loading Final Fantasy XV - Valse di Fantasica\n","Loading Diabolik Lovers - More Blood BGM\n","Loading Mamamoo - Egotistic (AnimeMidi)\n","Loading Shingeki no Koyojin Jiyuu no Tsubasa\n","Loading BlackPink - Stay\n","Loading UtaPri - Winter Blossom (Official)\n","Loading UtaPri Believe Heart (Easy)\n","Loading Kamigami no Asobi - Reason for\n","Loading Brave shine - Instrumental\n","Loading Omake-Pfadlib\n","Loading AnoHana - Aoi shiori\n","Loading Moomin - Yume no Sekai He (AnimeMidi)\n","Loading Sword Art Online - Gracefully\n","Loading UtaPri Maji Love 2000-\n","Loading UtaPri Maigo no kokoro\n","Loading Ken ga Kimi - Namida\n","Loading UtaPri Orange Rhapsody\n","Loading BTS - Crystal Snow (AnimeMidi)\n","Loading Sadness and Sorrow \n","Loading UtaPri Shizuku to Hamon no Namida Ame\n","Loading UtaPri Nanairo no Compass (TV Size)\n","Loading Diabolik Lovers - Gin no Bara-1\n","Loading UtaPri Crystal Time (TV Size)\n","Loading Love Live - Shocking Party\n","Loading BTS - Epiphany (AnimeMidi)\n","Loading UtaPri Maji Love 1000- Hard\n","Loading Sword Art Online - Niji no Oto\n","Loading UtaPri Knocking on the mind\n","Loading Kimi ni Todoke ENDING 2 - MIDI\n","Loading Kimi ni Todoke - Reaching You\n","Loading Tsubasa Chronicles - Ring your song (Piano)\n","Loading Sora ni Hikaru (From \\\"Clannad\\\") \n","Loading Hikaru Nara\n","Loading Diabolik Lovers - Track 2\n","Loading SHINee - I'm With You (AnimeMidi)\n","Loading Diabolik Lovers - Mr Sadistic Night\n","Loading Hideaki Tokunaga - Rainy Blue\n","Loading Gokukoku no Brynhildr - Memories (Midi edit)\n","Loading UtaPri Brand New Melody\n","Loading Despair - Naruto\n","Loading Diabolik Lovers - Martyr (AnimeMidi)\n","Loading EXO - Universe (AnimeMidi)\n","Loading UtaPri - Maji Love Revolution-1\n","Loading Domestic na Kanojo - Kawaki wo Ameku (AnimeMidi)\n","Loading Hyouka - Yasashisa no Riyuu \n","Loading Hyouka - Madoromi no Yakusoku\n","Loading UtaPri Mirai Chizu (Original)\n","Loading Swordland - SAO\n","Loading UtaPri Orpheus\n","Loading UtaPri Crystal Time (Orchestra)\n","Loading Mahou Shoujo Madoka Magica - Kimi no Gin no Niwa\n","Loading Angel Beats - Ichiban no Takaramono (AnimeMidi)\n","Loading Heart Realize - Noragami copy\n","Loading Howl's Moving Castle - Sekai no Yakusoku (AnimeMidi)\n","Loading Brave Song MIDI\n","Loading UtaPri Dreamer's Symphony-1\n","Loading Kokia - Ai no Melody\n","Loading Kimi no Na Wa - Zen Zen Zense (Synthesia)\n","Loading Big Bang - If You\n","Loading Ninelie Midi\n","Loading UtaPri - Canon (Easy)\n","Loading EXO - Lotto\n","Loading Sword Art Online - A Tiny Love\n","Loading Eye-Water AOT\n","Loading UtaPri Mirai Chizu (Hard)\n","Loading Brothers Conflict 14 to 1 (Easy)\n","Loading Sword Art Online - She is Still Sleeping\n","Loading Diabolik Lovers - Kindan no 666\n","Loading Lost My Pieces\n","Loading Diabolik Lovers - Floating Pain (AnimeMidi)\n","Loading Sword Art Online - At Nightfall\n","Loading UtaPri Maji Love 1000- Easy\n","Loading Mirai - Orange\n","Loading Overfly - SAO - MIDI\n","Loading Sword Art Online - Is This Love\n","Loading Yuri on Ice - History Maker (AnimeMidi)\n","Loading Undertale - His Theme (AnimeMidi)\n","Loading Ushio\n","Loading YouSeeBIGGIRL (From \\\"Attack on Titan\\\")\n","Loading Crossing Field (From \\\"Sword Art Online\\\")\n","Loading Kuroshitsuji - Missed You\n","Loading Korra Finale (Legend of Korra)\n","Loading Diabolik Lovers - BGM\n","Loading Sword Art Online - Sleeping Knights-1\n","Loading EXO - Monster\n","Loading Diabolik Lovers - Affection (AnimeMidi)\n","Loading Mystic Messenger - Mysterious Messenger (AnimeMidi)\n","Loading Akatsuki no Yona - Akatsuki (AnimeMidi)\n","Loading UtaPri Poison Kiss (Easy)\n","Loading Koutetsujou no Kabaneri - Opening\n","Loading While You Were Sleeping - When Night Falls\n","Loading Egoist - Euterpe ~Silence~ & Departures ~ Blessing\n","Loading Accel World - Bye Bye\n","Loading Gundam Unicorn - EGO\n","Loading Guren no Yumiya (From\\\"Attack on Titan\\\")\n","Loading Diabolik Lovers - Midnight Pleasure\n","Loading Tokyo Ghoul - Unravel (TehIshter)\n","Loading Orange - Hikari no Hahen\n","Loading Unjust Life \n","Loading Amnesia - Zoetrope (Easy)\n","Loading Continued Story - Code Geass\n","Loading Krone \n","Loading Diabolik Lovers More Blood - Quiet Hours\n","Loading Avatar Theme (The Last Airbender)\n","Loading UtaPri Mirai Chizu (Easy)\n","Loading UtaPri Quartet Night\n","Loading Tokyo Ghoul Unravel\n","Loading Stray Kids - Voices\n","Loading Kuroko no Basket - Punky Funky Love (AnimeMidi)\n","Loading Lull Soshite Bokurawa\n","Loading Shigatsu wa Kimi no Uso - Shigatsu wa Kimi no Uso\n","Loading Vocaloid - Ikanaide (AnimeMidi)\n","Loading Mirai Nikki - Here With You\n","Loading Shirushi - Sword Art Online 2 \n","Loading Grimms Note - Wasureji no Kotonoha\n","Loading Death Note - The World \n","Loading Shelter - Porter Robinson & Madeon\n","Loading Anime Medley for Piano 2016\n","Loading Mitsuba no Musubime\n","Loading Planetes Midi\n","Loading Diabolik Lovers - Sad Memories\n","Loading UtaPri Heavens\n","Loading A Tender Feeling\n","Loading Kuusou Mesorogiwi\n","Loading Vocaloid - Ikanaide (Solo)\n","Loading Fujita Maiko - Hotaru\n","Loading Sekai wa Koi ni Ochite Iru\n","Loading Yake Ochinai Tsubasa MIDI\n","Loading Guilty Crown - Pf-AdLib IV\n","Loading UtaPri Poison Kiss\n","11.2\n","11.2\n","11.2\n","11.4\n","11.4\n","11.4\n","11.2\n","11.2\n","11.4\n","11.4\n","11.4\n","11.4\n","11.4\n","11.4\n","11.4\n","11.2\n","11.4\n","11.4\n","11.4\n","11.4\n","11.4\n","11.4\n","11.4\n","11.4\n","11.4\n","11.4\n","11.4\n","11.4\n","11.4\n","11.4\n","11.4\n","11.4\n","11.4\n","11.4\n","11.4\n","11.4\n","11.4\n","11.4\n","11.4\n","11.4\n","11.2\n","11.4\n","11.4\n","11.2\n","11.4\n","11.4\n","11.4\n","11.4\n","11.4\n","11.4\n","E4\n","10.1\n","F#3\n","B4\n","B4\n","G4\n","A4\n","B4\n","B4\n","B4\n","B4\n","B4\n","B4\n","B4\n","F#5\n","G4\n","G4\n","B4\n","B4\n","C#5\n","B4\n","E5\n","F#5\n","B4\n","B4\n","B4\n","B4\n","B4\n","E5\n","B4\n","E-5\n","C#5\n","C#5\n","B4\n","E4\n","B4\n","B4\n","B4\n","B4\n","E4\n","B4\n","E5\n","0.4\n","4.8\n","10.3\n","B4\n","G#5\n","A4\n","B4\n","F#5\n","B4\n","F#5\n","E5\n","E5\n","E5\n","E5\n","A4\n","A4\n","B4\n","A4\n","D5\n","A4\n","D5\n","C#5\n","B-4\n","B-4\n","G#4\n","B4\n","E4\n","A4\n","A4\n","A4\n","G4\n","A4\n","B-4\n","A4\n","G4\n","D4\n","G4\n","B4\n","A4\n","A4\n","G4\n","A4\n","C#5\n","B4\n","G4\n","G4\n","D3\n","F#3\n","D6\n","D4\n","G4\n","C4\n","E4\n","F4\n","5.7.0\n","9.2\n","B3\n","6.9\n","G5\n","D5\n","A4\n","0.5\n","G5\n","6\n","9.2\n","G3\n","B2\n","G#4\n","5.9\n","4.7\n","G5\n","3\n","2\n","G3\n","5\n","C#3\n","G3\n","D3\n","8\n","9\n","G5\n","D3\n","9.2\n","F2\n","7.11.2\n","6\n","G5\n","D3\n","4\n","B2\n","9\n","6.9\n","G3\n","D3\n","D3\n","A3\n","E2\n","2.5\n","4\n","G3\n","D3\n","D5\n","4.7\n","F2\n","G5\n","D3\n","E3\n","F1\n","E4\n","9.1.4\n","5.10\n","G3\n","6.9\n","7.10\n","A2\n","0.4.7\n","9\n","10.2\n","2\n","G#5\n","F5\n","B4\n","9.2\n","1.4\n","8\n","F#3\n","G4\n","C#4\n","3.8\n","3.8\n","E4\n","D5\n","G3\n","8.0\n","3\n","10\n","G2\n","7.10.2\n","5.8.0\n","3.6\n","11.4\n","8\n","10\n","7.10\n","5\n","8\n","8\n","B-2\n","B-2\n","10\n","G#5\n","B-3\n","10.3\n","7\n","B1\n","G#4\n","C4\n","G#4\n","G#5\n","C5\n","G4\n","G#3\n","B-3\n","B5\n","G4\n","B-3\n","G#5\n","G4\n","B-4\n","10\n","C3\n","G#4\n","E-5\n","G#3\n","C5\n","B-4\n","C#5\n","G3\n","E-5\n","B-1\n","0.3\n","A4\n","C4\n","1.4\n","B-1\n","C4\n","C2\n","G#4\n","G3\n","B-3\n","G4\n","B-3\n","C5\n","B-2\n","11.2\n","F3\n","0\n","E-4\n","E-4\n","E-4\n","3\n","B-5\n","10.3\n","E-3\n","10\n","F5\n","10\n","B-3\n","0.3\n","B-3\n","C4\n","A5\n","B-3\n","0.5\n","E-4\n","C4\n","0.3\n","G#2\n","E-3\n","E-5\n","E-3\n","5.10\n","C#3\n","E-4\n","E-5\n","C#4\n","E-5\n","G#2\n","G#4\n","C#3\n","F3\n","E-4\n","C4\n","5.10\n","F5\n","B-3\n","G#6\n","10.2\n","3.7\n","3.7\n","E-3\n","5.10\n","E-3\n","8\n","B-5\n","E-3\n","B-5\n","G3\n","E-4\n","A4\n","B-3\n","5\n","F5\n","G3\n","B3\n","G#3\n","C#2\n","E-4\n","F2\n","B-4\n","C#3\n","G#3\n","B-3\n","B-3\n","C4\n","E-5\n","G#4\n","G5\n","B-4\n","E-4\n","B-4\n","B-4\n","B-3\n","G4\n","D4\n","F4\n","B-4\n","E-3\n","B-2\n","E-4\n","F5\n","F5\n","B-4\n","G#2\n","E-5\n","G#4\n","C#4\n","G4\n","G#6\n","F4\n","G#3\n","2.6.9\n","10.3\n","C3\n","G3\n","D5\n","B5\n","10.3\n","G#3\n","8.10\n","3.7\n","G#5\n","D3\n","10.0\n","G2\n","E-3\n","8.0\n","G3\n","2.6\n","G5\n","2.6\n","G2\n","G3\n","8\n","10\n","7\n","B-2\n","10\n","1.6\n","3\n","8\n","8.10.3\n","B-2\n","E-3\n","F#4\n","G#5\n","B3\n","G3\n","10\n","C3\n","G3\n","C4\n","3\n","D6\n","D5\n","F2\n","G2\n","B-1\n","G#4\n","G#3\n","B-3\n","B-3\n","G4\n","B-2\n","G#4\n","F3\n","G#4\n","B3\n","G#5\n","9.11.1\n","B-2\n","F4\n","G5\n","E-5\n","B-4\n","8\n","E-3\n","E-5\n","B-5\n","G#2\n","10\n","D5\n","D4\n","G4\n","G#4\n","5.8\n","E-5\n","C4\n","G4\n","0\n","C3\n","B-2\n","G4\n","2.7\n","F2\n","E-4\n","3\n","B-5\n","B-3\n","G3\n","B-3\n","G#4\n","G#4\n","E-4\n","F4\n","G4\n","10\n","B-2\n","F3\n","G#4\n","C4\n","E-4\n","E-4\n","E-4\n","F2\n","F2\n","3\n","B-2\n","B-2\n","D4\n","D4\n","7.10.2\n","D4\n","F4\n","B-2\n","F3\n","G4\n","B-4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jGFg2wKq0xqd","colab_type":"text"},"source":["#Download files"]},{"cell_type":"code","metadata":{"id":"hc9DAEdy01k1","colab_type":"code","outputId":"c10f8ca7-379e-48d0-ee7c-83b546127009","executionInfo":{"status":"ok","timestamp":1585885996917,"user_tz":240,"elapsed":30304,"user":{"displayName":"Thang Pham","photoUrl":"https://lh6.googleusercontent.com/-m9OaFsJMfho/AAAAAAAAAAI/AAAAAAAAAC4/zgzWztcdT78/s64/photo.jpg","userId":"14610559106662224301"}},"colab":{"base_uri":"https://localhost:8080/","height":142}},"source":["from google.colab import files\n","from google.colab import drive\n","\n","# files.download('test.mid')\n","drive.mount('/content/gdrive',force_remount=True)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ccxCHRTk1A6f","colab_type":"code","outputId":"2d06bde7-1e7b-42ec-bd29-8d47bd932c11","executionInfo":{"status":"ok","timestamp":1585878745424,"user_tz":240,"elapsed":2207,"user":{"displayName":"Thang Pham","photoUrl":"https://lh6.googleusercontent.com/-m9OaFsJMfho/AAAAAAAAAAI/AAAAAAAAAC4/zgzWztcdT78/s64/photo.jpg","userId":"14610559106662224301"}},"colab":{"base_uri":"https://localhost:8080/","height":101}},"source":["!zip models.zip models/*\n","!cp models.zip '/content/gdrive/My Drive/'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\tzip warning: name not matched: models/*\n","\n","zip error: Nothing to do! (models.zip)\n","cp: cannot stat 'models.zip': No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"roOec2VttSJ9","colab_type":"code","outputId":"da6019a7-167d-493c-b284-21cc88b99ef4","executionInfo":{"status":"ok","timestamp":1585886130244,"user_tz":240,"elapsed":129266,"user":{"displayName":"Thang Pham","photoUrl":"https://lh6.googleusercontent.com/-m9OaFsJMfho/AAAAAAAAAAI/AAAAAAAAAC4/zgzWztcdT78/s64/photo.jpg","userId":"14610559106662224301"}},"colab":{"base_uri":"https://localhost:8080/","height":479}},"source":["!unzip /content/gdrive/My\\ Drive/models.zip"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Archive:  /content/gdrive/My Drive/models.zip\n","   creating: models/\n","  inflating: models/model-01-4.68-4.62.hdf5  \n","  inflating: models/model-02-4.56-4.59.hdf5  \n","  inflating: models/model-03-4.51-4.54.hdf5  \n","  inflating: models/model-04-4.42-4.51.hdf5  \n","  inflating: models/model-05-4.35-4.51.hdf5  \n","  inflating: models/model-06-4.28-4.55.hdf5  \n","  inflating: models/model-07-4.21-4.51.hdf5  \n","  inflating: models/model-08-4.10-4.55.hdf5  \n","  inflating: models/model-09-3.97-4.67.hdf5  \n","  inflating: models/model-10-3.84-4.68.hdf5  \n","  inflating: models/model-11-3.65-4.77.hdf5  \n","  inflating: models/model-12-3.47-4.72.hdf5  \n","  inflating: models/model-13-3.26-4.91.hdf5  \n","  inflating: models/model-14-3.05-4.88.hdf5  \n","  inflating: models/model-15-2.82-5.22.hdf5  \n","  inflating: models/model-16-2.58-5.50.hdf5  \n","  inflating: models/model-17-2.31-5.47.hdf5  \n","  inflating: models/model-18-2.05-5.94.hdf5  \n","  inflating: models/model-19-1.79-6.20.hdf5  \n","  inflating: models/model-20-1.53-6.50.hdf5  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MQ7LacWWK_Z4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":911},"outputId":"2796843a-627c-4d6a-b94c-011e06e14fe3","executionInfo":{"status":"ok","timestamp":1585888560134,"user_tz":240,"elapsed":62428,"user":{"displayName":"Thang Pham","photoUrl":"https://lh6.googleusercontent.com/-m9OaFsJMfho/AAAAAAAAAAI/AAAAAAAAAC4/zgzWztcdT78/s64/photo.jpg","userId":"14610559106662224301"}}},"source":["!pip install tensorflow==1.14"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==1.14\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n","\u001b[K     |████████████████████████████████| 109.2MB 27kB/s \n","\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.1)\n","Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n","\u001b[K     |████████████████████████████████| 491kB 41.5MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.0.8)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.3.3)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.18.2)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n","Collecting tensorboard<1.15.0,>=1.14.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 49.6MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.9.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.34.2)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.10.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.27.2)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.2.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (46.0.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.0)\n","Installing collected packages: tensorflow-estimator, tensorboard, tensorflow\n","  Found existing installation: tensorflow-estimator 2.2.0rc0\n","    Uninstalling tensorflow-estimator-2.2.0rc0:\n","      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n","  Found existing installation: tensorboard 2.2.0\n","    Uninstalling tensorboard-2.2.0:\n","      Successfully uninstalled tensorboard-2.2.0\n","  Found existing installation: tensorflow 2.2.0rc2\n","    Uninstalling tensorflow-2.2.0rc2:\n","      Successfully uninstalled tensorflow-2.2.0rc2\n","Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["tensorboard","tensorflow"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"EHQvc441Ug8k","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}